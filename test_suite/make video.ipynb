{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = 'GOPR0485.MP4'\n",
    "TEST_IMG_PATH = './test2/test_IMG/'\n",
    "DRIVE_TEST_CSV_PATH = './test2/driving_test.csv'\n",
    "TEST_PREDICT_PATH = './test2/test_predict/'\n",
    "\n",
    "WEIGHTS = 'model-weights-Vtest.h5'\n",
    "EVAL_SAMPLE_SIZE = 100 # Number of samples to evaluate to compute MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing helpers\n",
    "def preprocess_image(image):\n",
    "#     image_cropped = image[100:440, :-90] # -> (380, 550, 3)\n",
    "#     image = cv2.resize(image_cropped, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    image = cv2.resize(image, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import nvidia_model\n",
    "from opticalHelpers import opticalFlowDenseDim3\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "# tf.python.control_flow_ops = tf\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), name=\"conv1\", strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\")`\n",
      "  name = 'conv1'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), name=\"conv2\", strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\")`\n",
      "  name = 'conv2'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), name=\"conv3\", strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\")`\n",
      "  name = 'conv3'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"conv4\", strides=(1, 1), padding=\"valid\", kernel_initializer=\"he_normal\")`\n",
      "  name = 'conv4'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"conv5\", strides=(1, 1), padding=\"valid\", kernel_initializer=\"he_normal\")`\n",
      "  name = 'conv5'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:58: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, name=\"fc1\", kernel_initializer=\"he_normal\")`\n",
      "  model.add(Dense(100, init = 'he_normal', name = 'fc1'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:60: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, name=\"fc2\", kernel_initializer=\"he_normal\")`\n",
      "  model.add(Dense(50, init = 'he_normal', name = 'fc2'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, name=\"fc3\", kernel_initializer=\"he_normal\")`\n",
      "  model.add(Dense(10, init = 'he_normal', name = 'fc3'))\n",
      "C:\\Users\\Yair\\Code\\speedChallenge\\test_suite\\model.py:66: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "  model.add(Dense(1, name = 'output', init = 'he_normal'))\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "n_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "with open(DRIVE_TEST_CSV_PATH, 'w') as csvfile:\n",
    "    fieldnames = ['image_path', 'time', 'speed']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for _ in range(int(n_frames/3)):\n",
    "        time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        success, image = cap.read()\n",
    "        if success:\n",
    "            image_path = os.path.join(TEST_IMG_PATH, str(time) + '.jpg')\n",
    "\n",
    "            # save image to IMG folder\n",
    "            cv2.imwrite(image_path, image)\n",
    "\n",
    "            # write row to driving.csv\n",
    "            writer.writerow({'image_path': image_path, \n",
    "                     'time':time,\n",
    "                     'speed':np.nan,\n",
    "                    })\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6615/6615 [26:20<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done creating test predictions\n"
     ]
    }
   ],
   "source": [
    "COUNT = 0\n",
    "data = pd.read_csv(DRIVE_TEST_CSV_PATH)\n",
    "data.time = data.time/1000 # convert from ms to seconds (for the following conditionals)\n",
    "for idx in tqdm(range(1, len(data) - 1)):\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "\n",
    "    img_diff = opticalFlowDenseDim3(x1, x2)\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "#     error = abs(prediction - y2)\n",
    "\n",
    "    predict_path = os.path.join(TEST_PREDICT_PATH, str(idx) + '.jpg')\n",
    "                                   \n",
    "    # overwrite the prediction of y2 onto image x2\n",
    "    # save overwritten image x2 to new directory ./data/predict\n",
    "\n",
    "                                   \n",
    "    # Make a copy \n",
    "    x2_copy = np.copy(x2)\n",
    "    \n",
    "    # to write new image via openCV\n",
    "    offset = 30\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    x2_copy = cv2.resize(x2_copy, (640, 480), interpolation = cv2.INTER_AREA)\n",
    "    cv2.putText(x2_copy, str(3.6*prediction[0][0])[:5] + ' km/h',(5,offset), font, 1,(0,0,0),1,cv2.LINE_AA)\n",
    "#     cv2.putText(x2_copy,'pred: ' + str(prediction[0][0])[:5],(5,offset), font, 1,(0,0,0),1,cv2.LINE_AA)\n",
    "#     cv2.putText(x2_copy,'truth: ' + str(y2)[:5],(5,offset * 2), font, 1,(0,20,255),1,cv2.LINE_AA)\n",
    "#     cv2.putText(x2_copy, 'error: ' + str(error[0][0])[:5], (5, offset*3),font, 1, (255, 0, 0),1, cv2.LINE_AA)\n",
    "    \n",
    "    # convert back to BGR for writing\n",
    "    x2_copy = cv2.cvtColor(x2_copy, cv2.COLOR_RGB2BGR)\n",
    "    COUNT += 1\n",
    "    cv2.imwrite(predict_path, x2_copy)\n",
    "    \n",
    "print('done creating test predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video movie-vTest.mp4\n",
      "[MoviePy] Writing video movie-vTest.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6614/6614 [01:56<00:00, 56.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: movie-vTest.mp4 \n",
      "\n",
      "done creating video\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "images = [TEST_PREDICT_PATH + str(i+1) + '.jpg' for i in range(0, COUNT - 1)]\n",
    "clip = ImageSequenceClip(images, fps=fps)\n",
    "clip.write_videofile(\"movie-vTest.mp4\", fps = fps)\n",
    "print('done creating video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
